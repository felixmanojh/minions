"""Interactive setup for minions configuration.

Provides guided model selection with:
- Ollama connectivity check
- Model download support
- Preset recommendations
"""

from __future__ import annotations

import json
import subprocess
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Optional

try:
    from rich.console import Console
    from rich.prompt import Prompt, Confirm
    from rich.table import Table
    from rich.panel import Panel
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False


CONFIG_PATH = Path(__file__).parent / "config" / "models.yaml"

# Recommended models by capability tier
RECOMMENDED_MODELS = {
    "minion": [
        ("qwen2.5-coder:7b", "Excellent code generation, fast (recommended)"),
        ("qwen2.5-coder:14b", "Better quality, needs more VRAM"),
        ("deepseek-coder:6.7b", "Strong alternative, good at explanations"),
        ("codellama:7b-code", "Meta's code model, well-tested"),
        ("starcoder2:7b", "Good for many languages"),
    ],
    "validator": [
        ("same", "Use minion model for validation (faster, simpler)"),
        ("codellama:7b-code", "Good for validation checks"),
        ("deepseek-coder:1.3b", "Lightweight validator"),
        ("qwen2.5-coder:1.5b", "Small but capable"),
    ],
}

PRESET_DESCRIPTIONS = {
    "lite": "Single model for both tasks. Fastest, lowest resource usage.",
    "standard": "Separate validator model. Better accuracy, moderate resources.",
    "expert": "Larger models. Best quality, requires 16GB+ VRAM.",
}


@dataclass
class OllamaStatus:
    """Ollama server status."""
    running: bool
    models: list[str]
    error: Optional[str] = None


def check_ollama() -> OllamaStatus:
    """Check if Ollama is running and get available models."""
    try:
        result = subprocess.run(
            ["curl", "-s", "http://127.0.0.1:11434/api/tags"],
            capture_output=True,
            timeout=5,
        )
        if result.returncode == 0:
            data = json.loads(result.stdout)
            models = [m["name"] for m in data.get("models", [])]
            return OllamaStatus(running=True, models=models)
        return OllamaStatus(running=False, models=[], error="Ollama not responding")
    except subprocess.TimeoutExpired:
        return OllamaStatus(running=False, models=[], error="Connection timeout")
    except Exception as e:
        return OllamaStatus(running=False, models=[], error=str(e))


def pull_model(model: str) -> bool:
    """Download a model via Ollama."""
    print(f"Downloading {model}... (this may take a while)")
    try:
        result = subprocess.run(
            ["ollama", "pull", model],
            timeout=600,  # 10 min timeout
        )
        return result.returncode == 0
    except subprocess.TimeoutExpired:
        print("Download timed out")
        return False
    except Exception as e:
        print(f"Download failed: {e}")
        return False


def generate_config(preset: str, minion_model: str, validator_model: Optional[str]) -> str:
    """Generate YAML configuration."""
    lines = [
        "# Minions Model Configuration",
        "#",
        "# Generated by: minions setup",
        "#",
        "# Override via environment:",
        "#   MINIONS_MODEL=qwen2.5-coder:14b",
        "#   MINIONS_VALIDATOR=codellama:7b",
        "#   MINIONS_NUM_CTX=65536",
        "",
        f"preset: {preset}",
        "",
        "validation:",
        "  max_retries: 1",
        "  notify_on_fail: true",
        "",
        "presets:",
    ]

    # Generate preset configs based on selection
    presets = {
        "lite": {
            "minion": {"model": minion_model, "temperature": 0.2, "max_tokens": 1024, "num_ctx": 32768},
            "validator": "same",
        },
        "standard": {
            "minion": {"model": minion_model, "temperature": 0.2, "max_tokens": 1024, "num_ctx": 32768},
            "validator": {"model": validator_model or minion_model, "temperature": 0.1, "max_tokens": 400, "num_ctx": 32768},
        },
        "expert": {
            "minion": {"model": minion_model, "temperature": 0.2, "max_tokens": 2048, "num_ctx": 65536},
            "validator": {"model": validator_model or "deepseek-coder:33b", "temperature": 0.1, "max_tokens": 400, "num_ctx": 32768},
        },
    }

    for preset_name, config in presets.items():
        lines.append(f"  {preset_name}:")
        lines.append("    minion:")
        for k, v in config["minion"].items():
            lines.append(f"      {k}: {v}")

        if config["validator"] == "same":
            lines.append("    validator: same")
        else:
            lines.append("    validator:")
            for k, v in config["validator"].items():
                lines.append(f"      {k}: {v}")
        lines.append("")

    return "\n".join(lines)


def run_setup_rich() -> dict:
    """Interactive setup with Rich UI."""
    console = Console()

    console.print(Panel.fit(
        "[bold blue]Minions Setup[/bold blue]\n"
        "Configure local LLM models for code tasks",
        border_style="blue",
    ))

    # Check Ollama
    console.print("\n[bold]Checking Ollama...[/bold]")
    status = check_ollama()

    if not status.running:
        console.print(f"[red]Ollama not running: {status.error}[/red]")
        console.print("\nStart Ollama with: [cyan]ollama serve[/cyan]")
        return {"success": False, "error": "Ollama not running"}

    console.print(f"[green]Ollama running with {len(status.models)} models[/green]")

    # Show installed models
    if status.models:
        table = Table(title="Installed Models")
        table.add_column("Model", style="cyan")
        for m in sorted(status.models):
            table.add_row(m)
        console.print(table)

    # Select preset
    console.print("\n[bold]Select a preset:[/bold]")
    for i, (name, desc) in enumerate(PRESET_DESCRIPTIONS.items(), 1):
        console.print(f"  {i}. [cyan]{name}[/cyan] - {desc}")

    preset_choice = Prompt.ask(
        "Choice",
        choices=["1", "2", "3", "lite", "standard", "expert"],
        default="2"
    )
    preset_map = {"1": "lite", "2": "standard", "3": "expert"}
    preset = preset_map.get(preset_choice, preset_choice)

    console.print(f"\nUsing preset: [bold cyan]{preset}[/bold cyan]")

    # Select minion model
    console.print("\n[bold]Select minion (generator) model:[/bold]")
    for i, (model, desc) in enumerate(RECOMMENDED_MODELS["minion"], 1):
        installed = "[green](installed)[/green]" if model in status.models else "[yellow](not installed)[/yellow]"
        console.print(f"  {i}. [cyan]{model}[/cyan] {installed}")
        console.print(f"     {desc}")

    console.print(f"  {len(RECOMMENDED_MODELS['minion']) + 1}. [cyan]Other[/cyan] - Enter custom model name")

    minion_choice = Prompt.ask(
        "Choice",
        default="1"
    )

    if minion_choice.isdigit():
        idx = int(minion_choice) - 1
        if idx < len(RECOMMENDED_MODELS["minion"]):
            minion_model = RECOMMENDED_MODELS["minion"][idx][0]
        else:
            minion_model = Prompt.ask("Enter model name")
    else:
        minion_model = minion_choice

    # Check if model needs download
    if minion_model not in status.models:
        if Confirm.ask(f"[yellow]{minion_model} not installed. Download now?[/yellow]"):
            if not pull_model(minion_model):
                console.print("[red]Download failed. Please install manually.[/red]")
                return {"success": False, "error": f"Failed to download {minion_model}"}
            status.models.append(minion_model)

    # Select validator model
    validator_model = None
    if preset != "lite":
        console.print("\n[bold]Select validator model:[/bold]")
        for i, (model, desc) in enumerate(RECOMMENDED_MODELS["validator"], 1):
            if model == "same":
                console.print(f"  {i}. [cyan]{model}[/cyan] - {desc}")
            else:
                installed = "[green](installed)[/green]" if model in status.models else "[yellow](not installed)[/yellow]"
                console.print(f"  {i}. [cyan]{model}[/cyan] {installed}")
                console.print(f"     {desc}")

        validator_choice = Prompt.ask("Choice", default="1")

        if validator_choice.isdigit():
            idx = int(validator_choice) - 1
            if idx < len(RECOMMENDED_MODELS["validator"]):
                validator_model = RECOMMENDED_MODELS["validator"][idx][0]
                if validator_model == "same":
                    validator_model = None
            else:
                validator_model = Prompt.ask("Enter model name")
        else:
            validator_model = validator_choice if validator_choice != "same" else None

        # Check if validator needs download
        if validator_model and validator_model not in status.models:
            if Confirm.ask(f"[yellow]{validator_model} not installed. Download now?[/yellow]"):
                if not pull_model(validator_model):
                    console.print("[red]Download failed. Using minion model for validation.[/red]")
                    validator_model = None

    # Generate and save config
    config_content = generate_config(preset, minion_model, validator_model)

    console.print("\n[bold]Configuration:[/bold]")
    console.print(Panel(config_content, title="models.yaml", border_style="dim"))

    if Confirm.ask("Save this configuration?", default=True):
        CONFIG_PATH.write_text(config_content)
        console.print(f"\n[green]Configuration saved to {CONFIG_PATH}[/green]")

        console.print("\n[bold green]Setup complete![/bold green]")
        console.print("Try: [cyan]minions polish yourfile.py --task docstrings[/cyan]")

        return {
            "success": True,
            "preset": preset,
            "minion": minion_model,
            "validator": validator_model or "same",
        }
    else:
        console.print("[yellow]Configuration not saved.[/yellow]")
        return {"success": False, "error": "User cancelled"}


def run_setup_simple() -> dict:
    """Simple text-based setup without Rich."""
    print("=" * 50)
    print("Minions Setup")
    print("=" * 50)

    # Check Ollama
    print("\nChecking Ollama...")
    status = check_ollama()

    if not status.running:
        print(f"ERROR: Ollama not running: {status.error}")
        print("Start Ollama with: ollama serve")
        return {"success": False, "error": "Ollama not running"}

    print(f"OK: Ollama running with {len(status.models)} models")

    # Show installed models
    if status.models:
        print("\nInstalled models:")
        for m in sorted(status.models):
            print(f"  - {m}")

    # Simple preset selection
    print("\nPresets:")
    print("  1. lite - Single model, fastest")
    print("  2. standard - Separate validator (recommended)")
    print("  3. expert - Larger models, best quality")

    preset_choice = input("\nSelect preset [2]: ").strip() or "2"
    preset = {"1": "lite", "2": "standard", "3": "expert"}.get(preset_choice, "standard")

    # Model selection
    print(f"\nRecommended minion model: qwen2.5-coder:7b")
    minion_model = input("Minion model [qwen2.5-coder:7b]: ").strip() or "qwen2.5-coder:7b"

    if minion_model not in status.models:
        dl = input(f"{minion_model} not installed. Download? [y/N]: ").strip().lower()
        if dl == "y":
            if not pull_model(minion_model):
                print("Download failed")
                return {"success": False, "error": f"Failed to download {minion_model}"}

    validator_model = None
    if preset != "lite":
        print("\nValidator model (or 'same' to use minion): codellama:7b-code")
        validator_model = input("Validator [codellama:7b-code]: ").strip() or "codellama:7b-code"
        if validator_model.lower() == "same":
            validator_model = None
        elif validator_model not in status.models:
            dl = input(f"{validator_model} not installed. Download? [y/N]: ").strip().lower()
            if dl == "y":
                if not pull_model(validator_model):
                    print("Download failed, using minion for validation")
                    validator_model = None

    # Save config
    config_content = generate_config(preset, minion_model, validator_model)
    print("\n--- Configuration ---")
    print(config_content)
    print("---")

    save = input("\nSave configuration? [Y/n]: ").strip().lower()
    if save != "n":
        CONFIG_PATH.write_text(config_content)
        print(f"\nSaved to {CONFIG_PATH}")
        print("\nSetup complete!")
        return {
            "success": True,
            "preset": preset,
            "minion": minion_model,
            "validator": validator_model or "same",
        }
    else:
        print("Configuration not saved.")
        return {"success": False, "error": "User cancelled"}


def run_setup() -> dict:
    """Run interactive setup (auto-selects Rich or simple)."""
    if RICH_AVAILABLE:
        return run_setup_rich()
    return run_setup_simple()


if __name__ == "__main__":
    result = run_setup()
    sys.exit(0 if result.get("success") else 1)
